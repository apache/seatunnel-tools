#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# DataX HDFS Writer to SeaTunnel HdfsFile Sink Conversion Template
# Based on core parameter configuration from SeaTunnel official documentation
# Template Type: HDFS Sink
# Version: 2.1
sink {
  HdfsFile {
    # ===== Required Parameters =====

    # HDFS cluster address (required)
    fs.defaultFS = "{{ datax.job.content[0].writer.parameter.defaultFS }}"

    # Output path (required)
    path = "{{ datax.job.content[0].writer.parameter.path }}"

    # ===== Core Configuration Parameters =====

    # File format type
    file_format_type = "{{ datax.job.content[0].writer.parameter.fileType | default('text') }}"

    # Field delimiter (required for text/csv format only)
    field_delimiter = "{{ datax.job.content[0].writer.parameter.fieldDelimiter | default('\t') }}"

    # Row delimiter (required for text format only)
    row_delimiter = "{{ datax.job.content[0].writer.parameter.rowDelimiter | default('\n') }}"

    # Compression codec
    compress_codec = "{{ datax.job.content[0].writer.parameter.compress | compress_mapper | default('none') }}"

    # File encoding
    encoding = "{{ datax.job.content[0].writer.parameter.encoding | default('UTF-8') }}"

    # Batch processing size
    batch_size = {{ datax.job.content[0].writer.parameter.batchSize | default(1000000) }}

    # ===== Optional Configuration Parameters =====

    # Temporary path - for transactional writing
    tmp_path = "/tmp/seatunnel"

    # Enable transaction to guarantee exactly-once semantics
    is_enable_transaction = true

    # Whether to write header (text/csv format only)
    enable_header_write = {{ datax.job.content[0].writer.parameter.header | default(false) }}
  }
}