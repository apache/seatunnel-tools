# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Custom conversion template from MySQL to Hive
# Supports extracting MySQL data source information from DataX and converting to Hive write configuration
# Syntax: Jinja2 style
# Version: 1.0

env {
  execution.parallelism = {{ datax.job.setting.speed.channel | default(1) }}
  job.mode = "BATCH"
}

source {
  Jdbc {
    url = "{{ datax.job.content[0].reader.parameter.connection[0].jdbcUrl[0] }}"
    driver = "com.mysql.cj.jdbc.Driver"
    user = "{{ datax.job.content[0].reader.parameter.username }}"
    password = "{{ datax.job.content[0].reader.parameter.password }}"
    query = "{{ datax.job.content[0].reader.parameter.querySql[0] | default('SELECT') }} {{ datax.job.content[0].reader.parameter.column | join(',') }} FROM {{ datax.job.content[0].reader.parameter.connection[0].table[0] }}"
    plugin_output = "source_table"
  }
}

sink {
  Hive {
    # Full table name, format: database.table_name
    #
    # Option 1: Direct specification (recommended)
    # table_name = "test_ods.test_table"

    # Option 2: Extract from DataX configuration (if available)
    # table_name = "{{ datax.job.content[0].writer.parameter.database | default('default') }}.{{ datax.job.content[0].writer.parameter.table | default('target_table') }}"

    # Option 3: Intelligently extract Hive table name from path
    # Use split and get filters to extract database name and table name
    # Step 1: Split path
    # Step 2: Get second-to-last part as database name, remove .db suffix
    # Step 3: Get last part as table name
    table_name = "{{ datax.job.content[0].writer.parameter.path | split('/') | get(-3) | replace('.db,') }}.{{ datax.job.content[0].writer.parameter.path | split('/') | get(-2) }}"

    # Hive Metastore configuration
    metastore_uri = "{{ datax.job.content[0].writer.parameter.metastoreUri | default('thrift://localhost:9083') }}"

    # Compression configuration
    compress_codec = "{{ datax.job.content[0].writer.parameter.compress | default('none') }}"

    # Hadoop configuration file paths (optional)
    # hdfs_site_path = "/etc/hadoop/conf/hdfs-site.xml"
    # hive_site_path = "/etc/hadoop/conf/hive-site.xml"

    # Hadoop configuration (optional)
    # hive.hadoop.conf = {
    #   "fs.defaultFS" = "{{ datax.job.content[0].writer.parameter.defaultFS | default('hdfs://localhost:9000') }}"
    # }

    # Source table name
    plugin_input = "source_table"
  }
}
